#!/usr/bin/env python
#
# Create job arrays from template files and parameter values provided on
# the command line.
#

import sys
import os
import re
import argparse
import logging
import errno
import StringIO
import contextlib
import json
import shutil

#
# The Scriptlet class is used to execute Python code found in the
# template files:
#
@contextlib.contextmanager
def stdoutIO(stdout=None):
    old = sys.stdout
    if stdout is None:
        stdout = StringIO.StringIO()
    sys.stdout = stdout
    yield stdout
    sys.stdout = old

class Scriptlet(object):

    def __init__(self, codeString, globalVars = {}, localVars = {}):
        self._codeString = codeString
        self._globalVars = globalVars
        self._localVars = localVars
        self._output = None
        self._hasBeenExecuted = False
        self._didProduceError = False

    def execute(self):
        self._hasBeenExecuted = True
        self._didProduceError = False
        self._output = None
        try:
            with stdoutIO() as s:
                exec(self._codeString, self._globalVars, self._localVars)
            self._output = s.getvalue()
        except Exception as E:
            self._output = str(E)
            self._didProduceError = True
        return not self._didProduceError

    def globalVars(self):
        return self._globalVars.viewitems()

    def localVars(self):
        return self._localVars.viewitems()

    def hasBeenExecuted(self):
        return self._hasBeenExecuted

    def didProduceError(self):
        return self._didProduceError

    def output(self):
        return self._output


class TemplateCache(object):

    _cached_content = dict()

    @classmethod
    def getTemplateContent(cls, path):
        if path != '-':
            path = os.path.abspath(path)
        if path in cls._cached_content:
            logging.debug('cached template %s used', path)
            return '' + cls._cached_content[path]
        logging.debug('initial read of template %s', path)
        if path == '-':
            content = sys.stdin.read()
        else:
            input_stream = open(path, 'r')
            content = input_stream.read()
            input_stream.close()
        cls._cached_content[path] = content
        return content


#
# Define our parameter list class:
#
class Parameter(object):

    __float_range_regex_str = r'(([+-]?\d+(\.\d*)?(e[+-]?\d+)?)(-([+-]?\d+(\.\d*)?(e[+-]?\d+)?)(/\d+|:[+-]?\d+(\.\d*)?))?)'
    __float_range_regex = re.compile('^'+__float_range_regex_str+'$')
    __float_range_list_regex = re.compile('^'+__float_range_regex_str+'(,'+__float_range_regex_str+')*$')

    __int_range_regex_str = r'(([+-]?\d+)(-([+-]?\d+)(/\d+|:[+-]?\d+)?)?)'
    __int_range_regex = re.compile('^'+__int_range_regex_str+'$')
    __int_range_list_regex = re.compile('^'+__int_range_regex_str+'((,'+__int_range_regex_str+')*)$')

    def __init__(self, parameter_name, parameter_value_string):
        # Check the parameter name:
        parameter_name = parameter_name.strip()
        if not parameter_name:
            raise ValueError('no name provided for parameter value: %s', parameter_value_string)
        self.parameter_name = parameter_name
        self.value_list = list()

        # Check the format:
        m = Parameter.__int_range_list_regex.match(parameter_value_string)
        if m is not None:
            # Integer ranges:
            for range in parameter_value_string.split(','):
                m = Parameter.__int_range_regex.match(range)
                #
                # Groups:
                #    2      start value
                #    4      end value
                #    5      step function
                #
                start_value = int(m.group(2))
                end_value = m.group(4)
                if end_value is not None:
                    end_value = int(end_value)
                    if start_value != end_value:
                        step = m.group(5)
                        if step is None or step[0] == ':':
                            #
                            # Range with step size:
                            #
                            if step is None:
                                inc = None
                            else:
                                inc = int(step[1:])
                            if start_value > end_value:
                                # Descending, so inc must be negative:
                                if inc is None:
                                    inc = -1
                                elif inc >= 0:
                                    raise ValueError('descending integer range requires negative non-zero step size')
                                while start_value >= end_value:
                                    if start_value not in self.value_list: self.value_list.append(start_value)
                                    start_value = start_value + inc
                            else:
                                # Ascending, so inc must be positive:
                                if inc is None:
                                    inc = 1
                                elif inc <= 0:
                                    raise ValueError('ascending integer range requires positive non-zero step size')
                                while start_value <= end_value:
                                    if start_value not in self.value_list: self.value_list.append(start_value)
                                    start_value = start_value + inc

                        elif step[0] == '/':
                            #
                            # Range divided into N values:
                            #
                            n_values = int(step[1:])
                            if n_values <= 1:
                                raise(ValueError('invalid integer range divisor: %d', n_values))

                            step = (end_value - start_value) / (n_values - 1)
                            if step == 0:
                                step = 1 if (end_value >= start_value) else -1

                            if start_value > end_value:
                                # Descending:
                                while start_value >= end_value:
                                    if start_value not in self.value_list: self.value_list.append(start_value)
                                    start_value = start_value + step
                            else:
                                # Ascending, so inc must be positive:
                                while start_value <= end_value:
                                    if start_value not in self.value_list: self.value_list.append(start_value)
                                    start_value = start_value + step

                        else:
                            raise ValueError('invalid integer range: %s', range)

                    else:
                        if start_value not in self.value_list: self.value_list.append(start_value)
                else:
                    if start_value not in self.value_list: self.value_list.append(start_value)
        else:
            m = Parameter.__float_range_list_regex.match(parameter_value_string)
            if m is not None:
                # Float ranges:
                for range in parameter_value_string.split(','):
                    m = Parameter.__float_range_regex.match(range)
                    #
                    # Groups:
                    #    2      start value
                    #    6      end value
                    #    9      step function
                    #
                    start_value = float(m.group(2))
                    end_value = m.group(6)
                    if end_value is not None:
                        end_value = float(end_value)
                        if start_value != end_value:
                            step = m.group(9)
                            if step is None or step[0] == ':':
                                #
                                # Range with step size:
                                #
                                if step is None:
                                    inc = None
                                else:
                                    inc = float(step[1:])
                                if start_value > end_value:
                                    # Descending, so inc must be negative:
                                    if inc is None:
                                        inc = -1.0
                                    elif inc >= 0:
                                        raise ValueError('descending float range requires negative non-zero step size')
                                    while start_value >= end_value:
                                        if start_value not in self.value_list: self.value_list.append(start_value)
                                        start_value = start_value + inc
                                else:
                                    # Ascending, so inc must be positive:
                                    if inc is None:
                                        inc = 1.0
                                    elif inc <= 0:
                                        raise ValueError('ascending float range requires positive non-zero step size')
                                    while start_value <= end_value:
                                        if start_value not in self.value_list: self.value_list.append(start_value)
                                        start_value = start_value + inc

                            elif step[0] == '/':
                                #
                                # Range divided into N values:
                                #
                                n_values = int(step[1:])
                                if n_values <= 1:
                                    raise(ValueError('invalid float range divisor: %d', n_values))

                                step = (end_value - start_value) / (n_values - 1)
                                if step == 0.0:
                                    step = 1.0 if (end_value >= start_value) else -1.0

                                if start_value > end_value:
                                    # Descending:
                                    while start_value >= end_value:
                                        if start_value not in self.value_list: self.value_list.append(start_value)
                                        start_value = start_value + step
                                else:
                                    # Ascending, so inc must be positive:
                                    while start_value <= end_value:
                                        if start_value not in self.value_list: self.value_list.append(start_value)
                                        start_value = start_value + step

                            else:
                                raise ValueError('invalid float range: %s', range)

                        else:
                            if start_value not in self.value_list: self.value_list.append(start_value)
                    else:
                        if start_value not in self.value_list: self.value_list.append(start_value)
            else:
                # List of strings:
                while len(parameter_value_string):
                    # Starts with quote?
                    if parameter_value_string[0] == '"' or parameter_value_string[0] == "'":
                        quote_char = parameter_value_string[0]
                        start_index = end_index = 1
                        found_end_quote = False
                        while end_index < len(parameter_value_string):
                            if parameter_value_string[end_index] == quote_char:
                                if last_char is None or last_char != '\\':
                                    # End of quoting:
                                    found_end_quote = True
                                    break
                            last_char = parameter_value_string[end_index]
                            end_index = end_index + 1
                        # End quote not found?
                        if not found_end_quote:
                            raise ValueError('invalid string value:  no ending quote: %s', parameter_value_string)
                        next_index = end_index + 1
                    else:
                        # No quotes, just find next comma:
                        start_index = 0
                        end_index = parameter_value_string.find(',')
                        if end_index == -1:
                            end_index = len(parameter_value_string)
                            next_index = end_index
                        else:
                            next_index = end_index + 1

                    self.value_list.append(parameter_value_string[start_index:end_index])
                    if next_index < len(parameter_value_string) and parameter_value_string[next_index] == ',':
                        parameter_value_string = parameter_value_string[next_index + 1:]
                    else:
                        parameter_value_string = parameter_value_string[next_index:]



def processInputTemplate(template_string, global_variables):
    """
    This function  scans through the incoming template string searching for blocks delimited by the "[{%" and "%}]"
    strings.  The contents of this block are expected to be Python code, which will be executed in a unique
    execution context populated with the given dictionary of global variables defining the input parameters.  A
    common local variable space is shared between all code blocks, so it is possible to calculate values that
    subsequent blocks will reference.  The local variable space starts out empty on each invocation of this
    function.

    If all is successful, the transformed template string is returned to the caller.  Otherwise, an exception
    will be raised describing the problem encountered.
    """
    try:
        searchFrom = 0
        global_variables_copy = dict(global_variables)
        local_variables = {}
        while ( True ):
            # Where's the next code block start?
            codeStart = template_string.find('[{%', searchFrom)
            if codeStart < 0:
                break

            # Where's the code block stop?
            codeEnd = template_string.find('%}]', codeStart)
            if codeEnd < 0:
                raise RuntimeError('unterminated code block in template')

            # Extract the code:
            code = template_string[codeStart + 3:codeEnd].strip()
            wholeLine = False
            if (codeStart == 0) or (template_string[codeStart - 1] == "\n"):
                # If this line was the first line OR the code block was preceded by a <NL>,
                # then we're possibly looking at a whole-line block.
                #
                # If the only characters following the code block are whitespace terminated by
                # a <NL>, then indicate as much and adjust the codeEnd index to be past that
                # terminal <NL> character.
                i = codeEnd + 3
                while i < len(template_string) and (template_string[i] <> "\n" and template_string[i].isspace()):
                    i = i + 1
                if template_string[i] == "\n":
                    codeEnd = i + 1
                    wholeLine = True
                else:
                    codeEnd = codeEnd + 3
            else:
                codeEnd = codeEnd + 3

            # Execute it:
            s = Scriptlet(code, global_variables_copy, local_variables)
            if not s.execute():
                raise RuntimeError('unable to execute code block (' + s.output() + '): ' + code)
            replacement = s.output()
            if not wholeLine:
                replacement = replacement.strip()

            # Replace the code:
            searchFrom = codeStart + len(replacement)
            if wholeLine:
                # If we're replacing a whole line, then an empty replacement sees the line being
                # removed entirely.  For a non-empty replacement, add the text plus a terminal <NL>
                # character:
                if replacement:
                    template_string = template_string[:codeStart] + replacement + template_string[codeEnd:]
                else:
                    template_string = template_string[:codeStart] + template_string[codeEnd:]
            else:
                # Simple replacment of an inline (not whole-line) code block:
                template_string = template_string[:codeStart] + replacement + template_string[codeEnd:]

        # All done:
        return template_string
    except Exception as E:
        raise RuntimeError('unable to generate job script template: ' + str(E))


TEMPLATING_OPTIONS_SHOULD_IGNORE_ERRORS = 1
TEMPLATING_OPTIONS_SHOULD_NOT_MATCH_PERMISSIONS = 2


def __writeInputTemplates(input_templates, global_variables, parameters_array, job_array_index, options, catalog_stream):
    # Get job index working directory setup:
    global_variables['JOB_ARRAY_INDEX'] = job_array_index
    
    if parameters_array is None or len(parameters_array) == 0:
        output_paths = []
        for input_template in input_templates:
            try:
                templated_content = processInputTemplate(TemplateCache.getTemplateContent(input_template), global_variables)
                output_path = TemplatePathHelper.templatePathToOutputPath(input_template, job_array_index)
                logging.debug('  writing generated content for %s to %s', input_template, output_path)
                with open(output_path, 'w') as output_stream:
                    output_stream.write(templated_content)
                if (options & TEMPLATING_OPTIONS_SHOULD_NOT_MATCH_PERMISSIONS) == 0 and not os.path.islink(output_path):
                    shutil.copymode(input_template, output_path)
                output_paths.append(output_path)
            except Exception as E:
                logging.error('failed to generate %s for job array index %d: %s', input_template, job_array_index, str(E))
                if (options & TEMPLATING_OPTIONS_SHOULD_IGNORE_ERRORS) == 0:
                    sys.exit(1)
        global_variables.pop('JOB_ARRAY_INDEX', None)
        if catalog_stream:
            logging.debug('  updating indexing catalog for job array index %d', job_array_index)
            catalog_stream.write('[{0:d}:{1:s}] {{ "globals": {2:s}, "files": {3:s} }}\n'.format(
                    job_array_index,
                    TemplatePathHelper.directoryPrefixForJobArrayIndex(job_array_index),
                    json.dumps(global_variables, separators=(',',':')),
                    json.dumps(output_paths, separators=(',',':')))
                )
        job_array_index = job_array_index + 1
    else:
        for array_params in parameters_array:
            output_paths = []
            output_dir = TemplatePathHelper.directoryPrefixForJobArrayIndex(job_array_index)
            
            # Copy the parameter array entry...
            globals = dict(array_params)
            # ...add-in the globals we were passed...
            globals.update(global_variables)
            # ...set the job array index.
            globals['JOB_ARRAY_INDEX'] = job_array_index
            for input_template in input_templates:
                try:
                    templated_content = processInputTemplate(TemplateCache.getTemplateContent(input_template), globals)
                    output_path = TemplatePathHelper.templatePathToOutputPath(input_template, job_array_index)
                    logging.debug('  writing generated content for %s to %s', input_template, output_path)
                    with open(output_path, 'w') as output_stream:
                        output_stream.write(templated_content)
                    if (options & TEMPLATING_OPTIONS_SHOULD_NOT_MATCH_PERMISSIONS) == 0 and not os.path.islink(output_path):
                        shutil.copymode(input_template, output_path)
                    output_paths.append(output_path)
                except Exception as E:
                    logging.error('failed to generate %s for job array index %d: %s', input_template, job_array_index, str(E))
                    if (options & TEMPLATING_OPTIONS_SHOULD_IGNORE_ERRORS) == 0:
                        sys.exit(1)
            globals.pop('JOB_ARRAY_INDEX', None)
            if catalog_stream:
                logging.debug('  updating indexing catalog for job array index %d', job_array_index)
                print(str(output_dir))
                catalog_stream.write('[{0:d}:{1:s}] {{ "globals": {2:s}, "files": {3:s} }}\n'.format(
                        job_array_index,
                        TemplatePathHelper.directoryPrefixForJobArrayIndex(job_array_index),
                        json.dumps(globals, separators=(',',':')),
                        json.dumps(output_paths, separators=(',',':')))
                    )
            job_array_index = job_array_index + 1
    return job_array_index


def processInputTemplates(input_templates, global_variables, parameters, parameters_array, job_array_index=1, options=0, catalog_stream=None):
    """
    This recursive function pops the first Parameter off the parameters list and loops over it,
    calling this function with each value set in the variables list and passing the now-smaller
    parameters list.  If, however, the parameters list is empty after popping the top element,
    the processInputTemplate() function is called on each of the input_templates.
    """
    if len(parameters) > 0:
        parameter = parameters[0]
        remaining_parameters = parameters[1:]
        if len(remaining_parameters) > 0:
            # Recurse down into the next named parameter:
            for pval in parameter.value_list:
                global_variables[parameter.parameter_name] = pval
                job_array_index = processInputTemplates(input_templates,
                	                                    global_variables,
                	                                    remaining_parameters,
                	                                    parameters_array,
                	                                    job_array_index=job_array_index,
                	                                    options=options,
                	                                    catalog_stream=catalog_stream)
            global_variables.pop(parameter.parameter_name, None)
        else:
            # No more named parameters, time to process the template files:
            for pval in parameter.value_list:
                global_variables[parameter.parameter_name] = pval
                job_array_index = __writeInputTemplates(input_templates, global_variables, parameters_array, job_array_index, options, catalog_stream)
            global_variables.pop(parameter.parameter_name, None)
    else:
        # Special case, all of the named parameters were single-valued:
        job_array_index = __writeInputTemplates(input_templates, global_variables, parameters_array, job_array_index, options, catalog_stream)
    return job_array_index



# Setup a map of logging levels to integer indices, and the index of the default:
log_level_map = ( logging.CRITICAL, logging.ERROR, logging.WARNING, logging.INFO, logging.DEBUG )
default_log_level = 1

# Define the CLI arguments we accept:
cli_parser = argparse.ArgumentParser(
                        description='generate templated job arrays',
                        epilog='A <param-spec> consists of <param-name>=<value-list>, where <param-name> uses any characters except equals (=).  The <value-list> is a comma-separated list of integer/float values; comma-separated list of integer/float ranges with optional step size (:1 or :1.5) or division count (/10); or comma-separated list of strings, optionally quote delimited.  ')
cli_parser.add_argument('--version',
                        action='version',
                        version='%(prog)s 1.0.0')
cli_parser.add_argument('--verbose', '-v',
                        dest='verbose_level',
                        default=0,
                        action='count',
                        help='increase the amount of output produced as this program executes')
cli_parser.add_argument('--quiet', '-q',
                        dest='quiet_level',
                        default=0,
                        action='count',
                        help='decrease the amount of output produced as this program executes')
cli_parser.add_argument('--catalog', '-c',
                        metavar='<filepath>',
                        dest='catalog_path',
                        help='filename to which the indexing catalog (that maps job array index to parameter values) should be written; use "-" to write the index to stdout, if not specified then no index is written')
cli_parser.add_argument('--append-to-catalog',
                        dest='should_append_to_catalog',
                        action='store_true',
                        default=False,
                        help='if the indexing catalog file exists, append to it rather than overwriting it')
cli_parser.add_argument('--array-index', '-i',
                        metavar='<integer>',
                        dest='array_index',
                        type=int,
                        default=1,
                        help='starting index for the job array')
cli_parser.add_argument('--use-flat-layout', '-f',
                        dest='use_flat_layout',
                        action='store_true',
                        default=False,
                        help='do not create subdirectories for each job array index, just put all generated files in the current directory')
cli_parser.add_argument('--prefix', '-P',
                        metavar='<prefix>',
                        dest='prefix',
                        default='./',
                        help='prefix the given string on every file generated/copied/symlinked by the program; e.g. for directory mode and "-P ./JOB_" the directories ./JOB_1, ./JOB_2, etc. would be generated (trailing path separators are very significant, as they imply a subdirectory and not a prefix on a filename)')
cli_parser.add_argument('--index-format-in-paths',
                        metavar='<python-conversion>',
                        dest='index_format_in_paths',
                        default=':d',
                        help='Python format conversion specification to turn the integers (like the job array index) into a file name component, e.g. ":04d" for names like "0001" and "0102"; default is ":d" for names like "1" and "102"')
cli_parser.add_argument('--ignore-templating-errors',
                        dest='should_ignore_templating_errors',
                        action='store_true',
                        default=False,
                        help='do not exit on templating errors, continue trying to generate the rest of the templated content')
cli_parser.add_argument('--no-match-permissions',
                        dest='should_match_permissions',
                        action='store_false',
                        default=True,
                        help='do NOT copy file permissions from the original template files to the generated files')

#
# Give the parameter options their own group:
#
cli_parser_parameters = cli_parser.add_argument_group(
                        title='job parameters',
                        description='options that communication job parameters to the templater')
#
# Add --yaml-parameters if this Python has support for it:
#
have_param_array_flags = []
try:
    from yaml import load as yaml_load
    try:
        from yaml import CLoader as yaml_loader
    except ImportError:
        from yaml import Loader as yaml_loader

    cli_parser_parameters.add_argument('--yaml-parameters',
                        metavar='<yaml-file>',
                        dest='yaml_parameters_file',
                        help='read the array of parameters from a YAML file')
    have_param_array_flags.append('--yaml-parameters')
except:
    pass

#
# Add --json-parameters if this Python has support for it:
#
cli_parser_parameters.add_argument('--json-parameters',
                metavar='<json-file>',
                dest='json_parameters_file',
                help='read the array of parameters from a JSON file')
have_param_array_flags.append('--json-parameters')

#
# Add --csv-parameters if this Python has support for it:
#
try:
    import csv

    cli_parser_parameters.add_argument('--csv-parameters',
                        metavar='<csv-file>',
                        dest='csv_parameters_file',
                        help='read the array of parameters from a CSV file; the first row should contain the variable names for each column')
    have_param_array_flags.append('--csv-parameters')
except:
    pass

#
# Add the named parameters option:
#
help_str = 'add a named parameter to the scan'
if len(have_param_array_flags) > 0:
    help_str = help_str + '; named parameters augment an array specified via ' + ', '.join(have_param_array_flags)
cli_parser_parameters.add_argument('--parameter', '-p',
                        metavar='<param-spec>',
                        dest='parameters',
                        action='append',
                        help=help_str)

#
# Directory mode options go in their own subgroup:
#
cli_parser_dirmode = cli_parser.add_argument_group(
                        title='directory mode',
                        description='options available when not doing flat layout')
cli_parser_dirmode.add_argument('--jobs-per-directory', '-j',
                        metavar='<count>',
                        dest='jobs_per_directory',
                        type=int,
                        default=0,
                        help='create a hierarchy of directories such that no more than this many job subdirectories appear in each leaf directory; e.g. for --jobs-per-directory=4 and 16 generated job subdirectories, the paths would be <prefix>/{0,1,2,3}/<job-array-index>, which each first-level directory under prefix having 4 job subdirectories')
cli_parser_dirmode.add_argument('--copy', '-C',
                        metavar='<filepath>',
                        dest='copy_files',
                        action='append',
                        help='copy the given path to each job subdirectory (can be specified multiple times)')
cli_parser_dirmode.add_argument('--symlink', '-s',
                        metavar='<filepath>',
                        dest='symlink_files',
                        action='append',
                        help='create a symbolic link to the given path in each job subdirectory (can be specified multiple times)')
cli_parser_dirmode.add_argument('--no-relative-targets',
                        dest='should_not_create_relative_symlinks',
                        action='store_true',
                        default=False,
                        help='for --symlink/-s, always use the absolute path of the target file/directory and not a relative path')
cli_parser_dirmode.add_argument('--array-base-index',
                        metavar='<index>',
                        dest='array_base_index',
                        type=int,
                        default=None,
                        help='when used in conjuncation with --jobs-per-directory/-j, this is the lowest possible index in the array; useful for working on a subset of a larger job array (using --array-index/-a, --array-size)')
cli_parser_dirmode.add_argument('--array-size',
                        metavar='<count>',
                        dest='array_size',
                        type=int,
                        default=0,
                        help='when used in conjuncation with --jobs-per-directory/-j, the hierarchy is structured as though there are this many jobs in the array; useful for working on a subset of a larger job array (using --array-index/-a, --array-base-index)')


#
# Template file(s) are provided as positional arguments:
#
cli_parser.add_argument(nargs='+',
                        metavar='<template-file>',
                        dest='input_templates',
                        help='filename of an input template that should be processed; use "-" for stdin')


# Parser CLI arguments:
cli_args = cli_parser.parse_args()


# Fixup logging verbosity if necessary:
logging_level = default_log_level + cli_args.verbose_level - cli_args.quiet_level
if logging_level < 0: logging_level = 0
elif logging_level >= len(log_level_map): logging_level = len(log_level_map) - 1
logging.basicConfig(format='[%(levelname)s] %(message)s', level=log_level_map[logging_level])


# Validate array index:
if cli_args.array_index < 1:
    logging.error('the starting array index must be a positive integer')
    sys.exit(errno.EINVAL)


# Validate options specific to directory mode:
if not cli_args.use_flat_layout:
    # Validate jobs-per-directory if specified:
    if cli_args.jobs_per_directory < 0:
        logging.error('invalid --jobs-per-directory/-j: %d', cli_args.jobs_per_directory)
        sys.exit(errno.EINVAL)

    # Validate the base index if present:
    if cli_args.array_base_index is None:
        cli_args.array_base_index = cli_args.array_index
    if cli_args.array_base_index <= 0:
        logging.error('invalid --array-base-index: %d', cli_args.array_base_index)
        sys.exit(errno.EINVAL)
    elif cli_args.array_index < cli_args.array_base_index:
        logging.error('starting array index is lower than the base index: %d < %d', cli_args.array_index, cli_args.array_base_index)
        sys.exit(errno.EINVAL)

    # Validate array size:
    if cli_args.array_size < 0:
        logging.error('invalid --array-size: %d', cli_args.array_size)
        sys.exit(errno.EINVAL)

    # Check to be sure all copy and symlink file sources actually exist:
    if cli_args.copy_files:
        for copy_file in cli_args.copy_files:
            if not os.path.exists(copy_file):
                logging.error('cannot copy %s: does not exist', copy_file)
                sys.exit(errno.EINVAL)
            if not (os.path.isfile(copy_file) or os.path.isdir(copy_file) or os.path.islink(copy_file)):
                logging.error('cannot copy %s: not a regular file, directory, or symbolic link', copy_file)
                sys.exit(errno.EINVAL)
    if cli_args.symlink_files:
        for symlink_file in cli_args.symlink_files:
            if not os.path.exists(symlink_file):
                logging.error('cannot symlink %s: does not exist', symlink_file)
                sys.exit(errno.EINVAL)

# No templates?
if cli_args.input_templates is None or len(cli_args.input_templates) == 0:
    logging.critical('no input templates were provided, so there is nothing to do')
    cli_parser.print_usage()
    sys.exit(errno.EINVAL)
input_templates = list()
for input_template in cli_args.input_templates:
    if input_template == '-' or os.access(input_template, os.R_OK):
        if input_template in input_templates:
            logging.error('the input template %s was specified multiple times', input_template)
            cli_parser.print_usage()
            sys.exit(errno.EINVAL)
        input_templates.append(input_template)
    else:
        logging.error('the input template %s is not readable', input_template)
        sys.exit(errno.EINVAL)
input_template_count = len(input_templates)
logging.info('%d input templates to process', input_template_count)


# Any parameter array to import?
parameters_array = []
has_yaml_params = 1 if (hasattr(cli_args, 'yaml_parameters_file') and cli_args.yaml_parameters_file) else 0
has_json_params = 1 if (hasattr(cli_args, 'json_parameters_file') and cli_args.json_parameters_file) else 0
has_csv_params = 1 if (hasattr(cli_args, 'csv_parameters_file') and cli_args.csv_parameters_file) else 0
if (has_yaml_params + has_json_params + has_csv_params) > 1:
    logging.error('only a single parameter array can be specified')
    sys.exit(errno.EINVAL)
if has_yaml_params:
    try:
        with open(cli_args.yaml_parameters_file, 'rb') as f:
            yaml_data = yaml_load(f, Loader=yaml_loader)
            if not isinstance(yaml_data, list):
                logging.error('a YAML parameter file must be an array of dictionaries')
                sys.exit(errno.EINVAL)
            for row in yaml_data:
                if not isinstance(row, dict):
                    logging.error('a YAML parameter file must be an array of dictionaries')
                    sys.exit(errno.EINVAL)
            parameters_array = yaml_data
    except Exception as E:
        logging.error('unable to read YAML parameter array: %s', str(E))
        sys.exit(errno.EINVAL)
elif has_json_params:
    try:
        with open(cli_args.json_parameters_file, 'rb') as f:
            json_data = json.loads(f.read())
            if not isinstance(json_data, list):
                logging.error('a JSON parameter file must be an array of dictionaries')
                sys.exit(errno.EINVAL)
            for row in json_data:
                if not isinstance(row, dict):
                    logging.error('a JSON parameter file must be an array of dictionaries')
                    sys.exit(errno.EINVAL)
            parameters_array = json_data
    except Exception as E:
        logging.error('unable to read JSON parameter array: %s', str(E))
        sys.exit(errno.EINVAL)
elif has_csv_params:
    try:
        with open(cli_args.csv_parameters_file, 'rb') as f:
            csv_reader = csv.DictReader(f)
            parameters_array.extend(csv_reader)
    except Exception as E:
        logging.error('unable to read CSV parameter array: %s', str(E))
        sys.exit(errno.EINVAL)


# No parameters?
if (cli_args.parameters is None or len(cli_args.parameters) == 0) and len(parameters_array) == 0:
    logging.critical('no parameters were provided, so this is not a parameter scan calculation')
    cli_parser.print_usage()
    sys.exit(errno.EINVAL)

global_variables = {}
final_parameters = []
if cli_args.parameters:
    logging.debug('%d initial parameters from CLI', len(cli_args.parameters))

    # Drop any empty parameters:
    parameters = filter(lambda p: len(p) != 0, [p.strip() for p in cli_args.parameters])
    if len(parameters) == 0 and len(parameters_array) == 0:
        logging.critical('no parameters were provided, so this is not a parameter scan calculation')
        cli_parser.print_usage()
        sys.exit(errno.EINVAL)
    logging.debug('%d parameters after empty filtering', len(cli_args.parameters))


    # Process the parameters:
    logging.debug('compiling parameters into value lists')
    compiled_parameters = []
    for parameter in parameters:
        logging.debug('compiling parameter specification: %s', parameter)

        # Split on the first equals sign:
        parameter = parameter.split('=', 1)

        # Must have two components:
        if len(parameter) < 2:
            logging.error('invalid parameter %s:  no value provided', parameter[0])
            sys.exit(errno.EINVAL)

        # Try to turn the value into a Parameter object:
        try:
            p = Parameter(parameter[0], parameter[1])
            compiled_parameters.append(p)
            logging.info('added parameter %s = %s', p.parameter_name, str(p.value_list))
        except Exception as E:
            logging.error('invalid parameter %s:  %s', parameter[0], str(E))
            sys.exit(errno.EINVAL)


    # Let's eliminate any single-valued parameters by coallescing them into the
    # global variable space; that way we don't need to recurse over them:
    for p in compiled_parameters:
        if len(p.value_list) == 1:
            global_variables[p.parameter_name] = p.value_list[0]
        else:
            final_parameters.append(p)
    logging.debug('global variable space after parameter reduction: %s', str(global_variables))


# Are we supposed to write out an indexing catalog?
catalog_stream = None
if cli_args.catalog_path:
    if cli_args.catalog_path == '-':
        catalog_stream = sys.stdout
        logging.debug('indexing catalog will be written to stdout')
    else:
        try:
            catalog_stream = open(cli_args.catalog_path, ('a' if cli_args.should_append_to_catalog else 'w'))
            logging.debug('indexing catalog will be written to %s', cli_args.catalog_path)
        except Exception as E:
            logging.error('unable to open indexing catalog %s for writing: %s', cli_args.catalog_path, str(E))
            sys.exit(errno.EPERM)


# So how many files are we going to generate?
param_combination_count = len(parameters_array) if parameters_array else 1
if final_parameters:
    param_combination_count = param_combination_count * reduce((lambda a, b: a * b), [len(p.value_list) for p in final_parameters], 1)
logging.info('total parameter combinations %d', param_combination_count)
if cli_args.array_size == 0:
    cli_args.array_size = param_combination_count
input_template_count = len(input_templates)
logging.info('will generate %d file(s) in %d indices', param_combination_count * input_template_count, param_combination_count)


# Create our functions that transforms input paths into output paths, based on
# the flat- versus subdirectory layout that was chosen:
if cli_args.use_flat_layout:
    class TemplatePathHelper(object):
        """
        This variant of TemplatePathHelper appends an underscore and the job array
        index onto the name of the file, sans extension.  For example, the
        template path 'input.xml' with job array index 24 becomes 'input_24.xml'.
        """

        index_to_string_format = '{0' + cli_args.index_format_in_paths + '}'
        path_prefix = cli_args.prefix
        path_prefix_is_dir = cli.args.prefix.endswith(os.sep)
        path_prefix_is_dir_created = False

        @staticmethod
        def mkdir_p(path, mode=0777):
            if path != '':
                # Split the path into components:
                path_components = os.path.split(path)
                if os.path.exists(path_components[0]):
                    os.mkdir(path, mode)
                else:
                    TemplatePathHelper.mkdir_p(path_components[0], mode)
                    os.mkdir(path, mode)
        @classmethod
        def directoryPrefixForJobArrayIndex(cls, job_array_index):
            return ''

        @classmethod
        def templatePathToOutputPath(cls, template_path, job_array_index):
            if cls.path_prefix_is_dir and not path_prefix_is_dir_created:
                if not os.path.exists(cls.path_prefix):
                    TemplatePathHelper.mkdir_p(job_subdirectory)
                path_prefix_is_dir_created = True

            if template_path == '-':
                return 'stdin_' + cls.index_to_string_format.format(job_array_index)
            path_components = os.path.split(template_path)
            filename_components = os.path.splitext(template_path)
            return filename_components[0] + '_' + cls.index_to_string_format.format(job_array_index) + filename_components[1]

else:
    class TemplatePathHelper(object):
        """
        This variant of TemplatePathHelper creates a directory (under the prefix specified
        by the user) with the job array index.  For example, the user provides a prefix of
        './JOBS/RUN1/', the template path is 'input.xml', with job array index 24 the
        path would be './JOBS/RUN1/24/input.xml'.

        The directory tree is created recursively so the prefix needn't be created ahead of
        time by the user.
        """

        index_to_string_format = '{0' + cli_args.index_format_in_paths + '}'
        jobs_per_directory = cli_args.jobs_per_directory
        dir_hierarchy_depth = None
        array_base_index = cli_args.array_base_index
        array_size = cli_args.array_size
        copy_files = cli_args.copy_files
        symlink_files = cli_args.symlink_files
        should_not_create_relative_symlinks = cli_args.should_not_create_relative_symlinks
        job_subdirectory_prefix = cli_args.prefix
        initialized_directories = []

        @staticmethod
        def mkdir_p(path, mode=0777):
            if path != '':
                # Split the path into components:
                path_components = os.path.split(path)
                if os.path.exists(path_components[0]):
                    os.mkdir(path, mode)
                else:
                    TemplatePathHelper.mkdir_p(path_components[0], mode)
                    os.mkdir(path, mode)

        @classmethod
        def directoryPrefixForJobArrayIndex(cls, job_array_index):
            if cls.dir_hierarchy_depth == 0:
                return cls.job_subdirectory_prefix + cls.index_to_string_format.format(job_array_index)

            # Zero-shift the index:
            zero_based_index = job_array_index - cls.array_base_index

            # Repeatedly divide by the number of jobs per directory, creating
            # new directories until the index is small enough:
            path_list = [cls.index_to_string_format.format(job_array_index)]
            count = cls.dir_hierarchy_depth
            while count > 0:
                index = zero_based_index / cls.jobs_per_directory
                path_list.insert(0, cls.index_to_string_format.format(index))
                zero_based_index = index
                count = count - 1
            return cls.job_subdirectory_prefix + os.path.join(*path_list)

        @classmethod
        def templatePathToOutputPath(cls, template_path, job_array_index):
            # First time through?  Stash the base index:
            if cls.dir_hierarchy_depth is None:
                # Determine how deep the tree will need to be:
                if cls.jobs_per_directory <= 0:
                    cls.dir_hierarchy_depth = 0
                else:
                    count = cls.array_size
                    depth = 0
                    while count > cls.jobs_per_directory:
                        depth = depth + 1
                        count = count / cls.jobs_per_directory
                    cls.dir_hierarchy_depth = depth
                logging.debug('directory hierarchy depth will be %d', cls.dir_hierarchy_depth)

            # Get the directory path:
            job_subdirectory = cls.directoryPrefixForJobArrayIndex(job_array_index)

            if job_subdirectory not in cls.initialized_directories:
                if os.path.exists(job_subdirectory):
                    raise RuntimeError('the job array subdirectory {0} already exists'.format(job_subdirectory))
                TemplatePathHelper.mkdir_p(job_subdirectory)

                # Handle copying-in any files specified by user:
                if cls.copy_files:
                    for src_file in cls.copy_files:
                        if os.path.isdir(src_file):
                            shutil.copytree(src_file, os.path.join(job_subdirectory, os.path.basename(src_file)))
                        else:
                            shutil.copy2(src_file, os.path.join(job_subdirectory, os.path.basename(src_file)))

                # Handle symlinking an files specified by user:
                if cls.symlink_files:
                    for target_file in cls.symlink_files:
                        if cls.should_not_create_relative_symlinks or os.path.isabs(target_file) or os.path.isabs(cls.job_subdirectory_prefix):
                            # Use absolute paths, period:
                            abs_target_file = os.path.realpath(target_file)
                        else:
                            # Attempt to find a relative path:
                            abs_target_file = os.path.realpath(target_file)
                            abs_job_directory = os.path.realpath(job_subdirectory)
                            # Find the common root:
                            common_root = os.path.commonprefix([abs_target_file, abs_job_directory])
                            if common_root and common_root != '/':
                                # Having a common root means we can construct a path that's
                                # relative
                                rel_target_file = os.path.relpath(abs_target_file, common_root)
                                rel_job_directory = os.path.relpath(abs_job_directory, common_root)
                                rel_target_path = ['..'] * (1 + rel_job_directory.count(os.sep))
                                rel_target_path.append(rel_target_file)
                                abs_target_file = os.path.join(*rel_target_path)
                            else:
                                abs_target_file = os.path.realpath(target_file)

                        os.symlink(abs_target_file, os.path.join(job_subdirectory, os.path.basename(target_file)))
                        logging.debug('created symlink to %s in %s', abs_target_file, job_subdirectory)

                cls.initialized_directories.append(job_subdirectory)
            if template_path == '-':
                return os.path.join(job_subdirectory, 'stdin')
            path_components = os.path.split(template_path)
            return os.path.join(job_subdirectory, path_components[1])


# Go ahead and do it!
templating_options = 0
if cli_args.should_ignore_templating_errors:
    templating_options = templating_options | TEMPLATING_OPTIONS_SHOULD_IGNORE_ERRORS
if not cli_args.should_match_permissions:
    templating_options = templating_options | TEMPLATING_OPTIONS_SHOULD_NOT_MATCH_PERMISSIONS
try:
    job_index = processInputTemplates(input_templates,
                                      global_variables,
                                      final_parameters,
                                      parameters_array,
                                      job_array_index=cli_args.array_index,
                                      options=templating_options,
                                      catalog_stream=catalog_stream)
    logging.info('next job array index in sequence would be %d', job_index)
except Exception as E:
    logging.error('failed while generating templated content: %s', str(E))
    sys.exit(1)
